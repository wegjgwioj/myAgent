 ResNet 之后的“继承者们”是如何在此基础上推陈出新的。

-----

### 第一部分：代码实战 —— 手写 Residual Block (残差块)

ResNet 的核心就在于那个“跳跃连接”。在代码中，它其实就是简单的一句加法：`out = out + x`。

但在实际工程中，有一个细节需要注意：**维度的匹配**。
如果主路径经过了下采样（图片变小了），或者改变了通道数，那么原始输入 $x$ 就无法直接和输出相加（矩阵形状不一样）。这时候，$x$ 也需要经过一个 $1 \times 1$ 的卷积来调整形状。

以下是 PyTorch 的标准实现：

```python
import torch
import torch.nn as nn

class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super(ResidualBlock, self).__init__()
        
        # === 1. 主路径 (Main Path) ===
        # 两个 3x3 卷积层，这是 VGG 的经典设计
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, 
                               stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, 
                               stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        # === 2. 快捷路径 (Shortcut / Skip Connection) ===
        self.shortcut = nn.Sequential()
        
        # 关键逻辑：如果维度不匹配，shortcut 也需要变身
        # 情况A：stride != 1 (图片尺寸变小了)
        # 情况B：in_channels != out_channels (通道数变了)
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, 
                          stride=stride, bias=False), # 1x1 卷积调整维度
                nn.BatchNorm2d(out_channels)
            )

    def forward(self, x):
        identity = x  # 备份输入数据 (这就是用来"抄近道"的数据)
        
        # 主路径计算
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        
        out = self.conv2(out)
        out = self.bn2(out)
        
        # === 3. 核心步骤：残差相加 (Element-wise Add) ===
        # 将主路径的结果与原始输入(或调整后的输入)相加
        out += self.shortcut(identity) 
        
        # 相加之后再做最后的激活
        out = self.relu(out)
        
        return out

# 测试一下
x = torch.randn(1, 64, 32, 32) # Batch=1, Channel=64, 32x32
# 假设我们想把通道数翻倍到 128，并且把尺寸减半
block = ResidualBlock(in_channels=64, out_channels=128, stride=2)
output = block(x)
print(f"输入形状: {x.shape}")
print(f"输出形状: {output.shape}") 
# 预期输出: torch.Size([1, 128, 16, 16])
```

-----

### 第二部分：深入应用 —— ResNet 的继承者们

ResNet 打开了深层网络的大门后，学术界在此基础上衍生出了三个非常重要的改进方向：**更稠密、更宽、更轻**。

#### 1\. DenseNet (稠密连接网络) —— 极致的特征复用

  * **核心思想**：ResNet 是做加法 (`x + y`)，DenseNet 则是做**拼接 (Concatenation)**。
  * **机制**：在 DenseNet 中，**每一层都接收前面所有层的输出作为输入**。第 $L$ 层的输入是之前 $L-1$ 层所有特征图的拼接。
  * **优点**：特征利用率极高，参数量比 ResNet 少得多（因为每一层都很窄）。
  * **缺点**：**内存占用极大**。因为一直拼接，特征图的通道数会像滚雪球一样越滚越大，计算时对显存很不友好。

#### 2\. ResNeXt —— 分组卷积 (更宽)

  * **核心思想**：结合了 VGG 的堆叠思想和 Inception (GoogLeNet) 的**多分支**思想。
  * **机制**：ResNet 的残差块是一条路走到黑，ResNeXt 把它拆成了**32条平行的细路**（即分组卷积 Group Convolution），每条路单独处理，最后再合起来。
  * **术语**：引入了 **Cardinality (基数)** 的概念。实验证明，增加分支数量（基数）比单纯增加深度或宽度更有效。
  * **现状**：在很多图像识别比赛中，ResNeXt 的表现往往优于 ResNet。

#### 3\. MobileNet —— 移动端的王者 (更轻)

  * **背景**：ResNet 虽然强，但太重了，没法跑在手机或嵌入式设备上。
  * **核心思想**：**深度可分离卷积 (Depthwise Separable Convolution)**。
      * 它把标准的卷积拆成了两步：
        1.  **Depthwise Conv**：每个卷积核只负责一个通道（不融合通道信息）。
        2.  **Pointwise Conv**：用 $1 \times 1$ 卷积把通道信息融合起来。
  * **效果**：参数量和计算量直接减少了 **8 到 9 倍**，但精度损失很小。
  * **MobileNet V2**: 更是直接引入了 ResNet 的“倒残差结构 (Inverted Residuals)”，是目前手机端 AI 应用（如手机相册分类、即时人脸识别）的绝对主力。

-----

### 总结建议

  * 如果你做**学术研究**或追求极致精度：首选 **ResNeXt** 或更现代的 **EfficientNet / Vision Transformer (ViT)**。
  * 如果你做**手机/树莓派应用**：无脑选 **MobileNet V2/V3**。
  * 如果你刚开始**搭模型**：**ResNet-50** 是永远不会错的基准线 (Baseline)，它就像瑞士军刀一样稳定好用。

这就是 CNN 从“能用”到“好用”再到“随处可用”的演进过程。